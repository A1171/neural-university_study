{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Сборка сети с предобученным эмбедингом и его тестирование."
      ],
      "metadata": {
        "id": "j6pNKOWJaeIo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFxvMY2t1FEn"
      },
      "outputs": [],
      "source": [
        "# Токенизатор для преобразование текстов в последовательности\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Функции-утилиты для работы с категориальными данными\n",
        "from tensorflow.keras import utils\n",
        "# Работа с массивами данных\n",
        "import numpy as np \n",
        "# Класс для конструирования последовательной модели нейронной сети\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Основные слои\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation ,Embedding,SpatialDropout1D,Flatten,Input,LSTM\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Функции операционной системы\n",
        "import os\n",
        "# Регулярные выражения\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка предобученного эмбеддинга glove-wiki-gigaword-50 через API gensim"
      ],
      "metadata": {
        "id": "v8STOlT7ap45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "wv = api.load('glove-wiki-gigaword-50')\n",
        "wv['beginning'].shape"
      ],
      "metadata": {
        "id": "8qC0FqCF1K3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08b8833-871b-44c2-a4c3-b46bab5b3d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка датасета"
      ],
      "metadata": {
        "id": "vjHoCTvKbMFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=20000)"
      ],
      "metadata": {
        "id": "BDYxyVr5W40J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка датасета средняя длинна и среднеквадратичное отклонение."
      ],
      "metadata": {
        "id": "pKlBA41EbSW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Med=0\n",
        "std=0\n",
        "for i in range(len(train_data)):\n",
        "  Med=Med+len(train_data[i])\n",
        "Med=Med/len(train_data)\n",
        "for i in range(len(train_data)):\n",
        "  std=std+(Med-len(train_data[i]))**2\n",
        "std=std**0.5\n",
        "std=std/len(train_data)\n",
        "print(Med,std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQlPS8U6xX6",
        "outputId": "32a5ac47-da20-4067-935f-57c0c8fcae7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238.71364 1.1162440026795242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка текстовых данных"
      ],
      "metadata": {
        "id": "OD4iY80Qble_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SequencyWords=100"
      ],
      "metadata": {
        "id": "FiJ1pwQIN7me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data2 = pad_sequences(train_data, maxlen=SequencyWords, padding='post', truncating='post') \n",
        "test_data2 = pad_sequences(train_data, maxlen=SequencyWords, padding='post', truncating='post')\n",
        "print(train_data2[0])\n",
        "print(train_data2[0].shape)\n",
        "print(test_data2[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wuzdSLnAAHV",
        "outputId": "93a7a3ef-630f-4c85-c76d-080d38c116a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    1    14    22    16    43   530   973  1622  1385    65   458  4468\n",
            "    66  3941     4   173    36   256     5    25   100    43   838   112\n",
            "    50   670     2     9    35   480   284     5   150     4   172   112\n",
            "   167     2   336   385    39     4   172  4536  1111    17   546    38\n",
            "    13   447     4   192    50    16     6   147  2025    19    14    22\n",
            "     4  1920  4613   469     4    22    71    87    12    16    43   530\n",
            "    38    76    15    13  1247     4    22    17   515    17    12    16\n",
            "   626    18 19193     5    62   386    12     8   316     8   106     5\n",
            "     4  2223  5244    16]\n",
            "(100,)\n",
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получение слоя керас из загруженного эмбединга."
      ],
      "metadata": {
        "id": "p0Nr_q00br73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wv_emb = wv.get_keras_embedding()"
      ],
      "metadata": {
        "id": "vhkp-D6KOuzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сборка полносвязной модели с предобученным эмбедингом"
      ],
      "metadata": {
        "id": "5Pud6pM0b4AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input((SequencyWords))\n",
        "x = wv_emb(input)\n",
        "x = SpatialDropout1D(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(100, activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "Dense(33, activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x= Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model=Model(input,x)\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=1e-4))"
      ],
      "metadata": {
        "id": "yFq8It9pOu2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_iG5JOvbZs9",
        "outputId": "d276a25c-9134-4f1b-a078-736e4742bfbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 50)           20000000  \n",
            "                                                                 \n",
            " spatial_dropout1d_3 (Spatia  (None, 100, 50)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               500100    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 50)               200       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 50)               200       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,506,001\n",
            "Trainable params: 505,601\n",
            "Non-trainable params: 20,000,400\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H72O6lGrOlI0",
        "outputId": "bb85d088-ee7c-4154-cfab-9376f464e366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data2, train_labels,validation_data=(test_data2, test_labels), epochs = 30, batch_size = 32)#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJaCHPFYEgKZ",
        "outputId": "597d897d-7306-4c30-f71f-4d777127a2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 10s 11ms/step - loss: 0.8591 - accuracy: 0.5054 - val_loss: 0.7128 - val_accuracy: 0.4915\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.8051 - accuracy: 0.5089 - val_loss: 0.7052 - val_accuracy: 0.4980\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7682 - accuracy: 0.5203 - val_loss: 0.7057 - val_accuracy: 0.4992\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.7457 - accuracy: 0.5267 - val_loss: 0.7038 - val_accuracy: 0.4980\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.7250 - accuracy: 0.5383 - val_loss: 0.7040 - val_accuracy: 0.4953\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.7153 - accuracy: 0.5441 - val_loss: 0.7034 - val_accuracy: 0.4971\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.7021 - accuracy: 0.5514 - val_loss: 0.7060 - val_accuracy: 0.4968\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6890 - accuracy: 0.5684 - val_loss: 0.7102 - val_accuracy: 0.5012\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6817 - accuracy: 0.5776 - val_loss: 0.7135 - val_accuracy: 0.5021\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6748 - accuracy: 0.5843 - val_loss: 0.7158 - val_accuracy: 0.5016\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6639 - accuracy: 0.6013 - val_loss: 0.7201 - val_accuracy: 0.4993\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.6594 - accuracy: 0.6092 - val_loss: 0.7270 - val_accuracy: 0.5019\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6551 - accuracy: 0.6121 - val_loss: 0.7256 - val_accuracy: 0.4992\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6521 - accuracy: 0.6158 - val_loss: 0.7283 - val_accuracy: 0.5017\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.6447 - accuracy: 0.6270 - val_loss: 0.7311 - val_accuracy: 0.4987\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.6421 - accuracy: 0.6325 - val_loss: 0.7378 - val_accuracy: 0.4996\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.6397 - accuracy: 0.6350 - val_loss: 0.7364 - val_accuracy: 0.5028\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.6323 - accuracy: 0.6440 - val_loss: 0.7352 - val_accuracy: 0.5040\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6290 - accuracy: 0.6506 - val_loss: 0.7476 - val_accuracy: 0.5030\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6213 - accuracy: 0.6597 - val_loss: 0.7491 - val_accuracy: 0.5002\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6165 - accuracy: 0.6607 - val_loss: 0.7534 - val_accuracy: 0.5005\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6093 - accuracy: 0.6690 - val_loss: 0.7672 - val_accuracy: 0.4985\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6036 - accuracy: 0.6760 - val_loss: 0.7749 - val_accuracy: 0.5006\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.6009 - accuracy: 0.6762 - val_loss: 0.7617 - val_accuracy: 0.5022\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5959 - accuracy: 0.6816 - val_loss: 0.7749 - val_accuracy: 0.5006\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.5913 - accuracy: 0.6890 - val_loss: 0.7875 - val_accuracy: 0.5010\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.5885 - accuracy: 0.6878 - val_loss: 0.7845 - val_accuracy: 0.4999\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.5799 - accuracy: 0.6960 - val_loss: 0.7880 - val_accuracy: 0.5007\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.5722 - accuracy: 0.7026 - val_loss: 0.7931 - val_accuracy: 0.5002\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5677 - accuracy: 0.7064 - val_loss: 0.7949 - val_accuracy: 0.5010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00477dcd90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKLcN5wE1LAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сборка LSTM модели с предобученным эмбедингом"
      ],
      "metadata": {
        "id": "UoBCPhYxcPJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input((SequencyWords))\n",
        "x = wv_emb(input)\n",
        "#x = SpatialDropout1D(0.2)(x)\n",
        "x = LSTM(200)(x)\n",
        "#x = Dropout(0.2)(x)\n",
        "x = Dense(33, activation=\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "#x = Dropout(0.1)(x)\n",
        "x= Dense(1,activation='sigmoid')(x)\n",
        "model=Model(input,x)\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=1e-4))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLKksQuRR27z",
        "outputId": "11695a49-ab93-466f-b6f2-2e94c69a0785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 50)           20000000  \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 200)               200800    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 33)                6633      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 33)               132       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,207,599\n",
            "Trainable params: 207,533\n",
            "Non-trainable params: 20,000,066\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data2, train_labels,validation_data=(test_data2, test_labels), epochs = 10, batch_size = 32)#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QEltbw7R2_Z",
        "outputId": "0e3413a0-0c8d-4338-86fd-87dd3e18ede5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 211s 266ms/step - loss: 0.6995 - accuracy: 0.5312 - val_loss: 0.7135 - val_accuracy: 0.5001\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 208s 267ms/step - loss: 0.6856 - accuracy: 0.5519 - val_loss: 0.8094 - val_accuracy: 0.4972\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 209s 267ms/step - loss: 0.6677 - accuracy: 0.5902 - val_loss: 0.7523 - val_accuracy: 0.5018\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 210s 268ms/step - loss: 0.6512 - accuracy: 0.6176 - val_loss: 0.7649 - val_accuracy: 0.4953\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 208s 266ms/step - loss: 0.6277 - accuracy: 0.6426 - val_loss: 0.8329 - val_accuracy: 0.4949\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.6044 - accuracy: 0.6719 - val_loss: 1.1893 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 206s 264ms/step - loss: 0.5872 - accuracy: 0.6841 - val_loss: 0.9673 - val_accuracy: 0.4985\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.5726 - accuracy: 0.7017 - val_loss: 0.9934 - val_accuracy: 0.4982\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.5609 - accuracy: 0.7105 - val_loss: 0.8521 - val_accuracy: 0.4953\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 207s 265ms/step - loss: 0.5534 - accuracy: 0.7160 - val_loss: 1.0086 - val_accuracy: 0.4961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0048514ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У LSTM точность повыше получается."
      ],
      "metadata": {
        "id": "KV9pQEEjcvO4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vChyp75XR3Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsEoaDwR1LKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1R3qoXX1LNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше эксперимент по восстановлению фраз"
      ],
      "metadata": {
        "id": "gNn-Dy8VAYbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_id = imdb.get_word_index()"
      ],
      "metadata": {
        "id": "MFjApaDLCIq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INDEX_FROM=3   # word index offset\n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "word_to_id[\"<UNUSED>\"] = 3\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "train_data_txt=[]\n",
        "test_data_txt=[]\n",
        "for i in range(len(train_data2)):\n",
        "  train_data_txt.append(' '.join(id_to_word[id] for id in train_data2[i]))\n",
        "for i in range(len(test_data2)):\n",
        "  test_data_txt.append(' '.join(id_to_word[id] for id in test_data2[i]))\n",
        "\n",
        "print(train_data_txt[4])\n",
        "print(test_data_txt[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Rll9cGjQ6oWb",
        "outputId": "f111c009-fb2c-44fd-baa0-97a90bc8d1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> begins better than it ends funny that the russian submarine crew <UNK> all other actors it's like those scenes where documentary shots br br spoiler part the message <UNK> was contrary to the whole story it just does not mesh br br <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}