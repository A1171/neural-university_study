{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Сравнение словарей с нормализацией слов и без нормализации слов, Выводы о предположительном влиянии нормализации на обчение нейросети."
      ],
      "metadata": {
        "id": "gt_RfiwtHRPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown                                      # Подключим функцию gdown\n",
        "gdown.download('https://drive.google.com/uc?id=17gbopCAOFT0c0NNXrihA-nLBNtjcfr3L', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=105TXd6PKqI9PUPnbgsUJsAJz-VmdvUyi', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1sSHlBjjwZ46A_YieKnrj8HiR50dfPrAg', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1YNMvEZyshkQQxwANK6mafk7Gu72pNg2a', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1ZALYWB2YhL5GizAUGi6mkYYUPtilO6eq', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1vPS9mqlQbsQBB6MwaO0SYPWY7lwj6Kt9', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=19Ff5bb5HcKHrxa1kWkkbSxPzjCLoQh_b', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1zfppFRnZ-42UUHioVSzTuS-2O4gfVdW6', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1ZyuTlNfEUNSqoy_klOHnfZDyZbViWXS7', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1dInkT-ZmHAHDZy_4TFroH0hLwINxQ1K6', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=106aXnq-BXPWgmepSfAtygQrWmxeSNVAk', None, quiet=True)      # Скачивание файла\n",
        "gdown.download('https://drive.google.com/uc?id=1EbxijjJgqPp1YQWd8qwX716uBnsmaSAc', None, quiet=True)      # Скачивание файла\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sxInZAqfwpoM",
        "outputId": "ce826b65-a2a2-4d1e-9154-58a9a06c12ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(Клиффорд_Саймак) Тестовая_2 вместе.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkBzxktaArW6",
        "outputId": "c767014a-bec6-49b0-d349-fc14c0889a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " sample_data\n",
            "'(Булгаков) Обучающая_5 вместе.txt'\n",
            "'(Булгаков) Тестовая_2 вместе.txt'\n",
            "'(Клиффорд_Саймак) Обучающая_5 вместе.txt'\n",
            "'(Клиффорд_Саймак) Тестовая_2 вместе.txt'\n",
            "'(Макс Фрай) Обучающая_5 вместе.txt'\n",
            "'(Макс Фрай) Тестовая_2 вместе.txt'\n",
            "'(О. Генри) Обучающая_50 вместе.txt'\n",
            "'(О. Генри) Тестовая_20 вместе.txt'\n",
            "'(Рэй Брэдберри) Обучающая_22 вместе.txt'\n",
            "'(Рэй Брэдберри) Тестовая_8 вместе.txt'\n",
            "'(Стругацкие) Обучающая_5 вместе.txt'\n",
            "'(Стругацкие) Тестовая_2 вместе.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymorphy2==0.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77gXWfTb_oyy",
        "outputId": "c1cbf982-9f57-4a20-cb76-7bac4e0c40a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2==0.8\n",
            "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from google.colab import drive\n",
        "# Функции операционной системы\n",
        "import os\n",
        "# Регулярные выражения\n",
        "import re"
      ],
      "metadata": {
        "id": "0sR7IkE1_pci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Парсинг текстов"
      ],
      "metadata": {
        "id": "Ei9qkV1AKHHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_DIR=\"/content/\""
      ],
      "metadata": {
        "id": "6p16V6a3__mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# В список добавляются имена классов\n",
        "CLASS_LIST = []\n",
        "\n",
        "# Здесь сохраняются тексты для обучения сети\n",
        "text_train = []\n",
        "\n",
        "# цикл для итерации по каждому имени текста в общей папке\n",
        "for file_name in os.listdir(FILE_DIR):\n",
        "\n",
        "    # Выделение имени класса и типа выборки из имени файла\n",
        "    m = re.match('(\\()(.+)(\\))(.+)(\\.txt)', file_name)# (\\S+)_\n",
        "    #\n",
        "    # Если выделение получилось, то файл обрабатывается\n",
        "    if m:\n",
        "        class_name=m[2]\n",
        "        #m1=re.match('(.+)(\\.txt)', file_name)\n",
        "        #type=\n",
        "        #if('Тестовая' in m[4]):\n",
        "        print(m[2],m[4])\n",
        "        # Добавление нового класса, если его еще нет в списке\n",
        "        if class_name not in CLASS_LIST:\n",
        "\n",
        "                # Выводится информационное сообщение о добавлении названия класса\n",
        "                CLASS_LIST.append(class_name)\n",
        "\n",
        "                # Инициализация соответствующих классу строк текста\n",
        "                text_train.append('')\n",
        "            # Поиск индекса класса для добавления содержимого файла в выборку\n",
        "        cls = CLASS_LIST.index(class_name)\n",
        "\n",
        "            # Выводится информационное сообщение о добавлении класса в список классов и текста к выборке\n",
        "        print(f'Добавление файла \"{file_name}\" в класс \"{CLASS_LIST[cls]}\"')\n",
        "\n",
        "            # оператор with - безопасное чтение каждого файла с текстом\n",
        "        with open(f'{FILE_DIR}/{file_name}', 'r') as f:\n",
        "\n",
        "                # Загрузка содержимого файла в строку\n",
        "                text = f.read()\n",
        "                text = text.replace('\\n', ' ')\n",
        "\n",
        "            # Добавление текста к соответствующей выборке класса. Концы строк заменяются на пробел\n",
        "        if('Обучающая' in m[4]):\n",
        "          text_train[cls] += ' ' + text\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWQbDi4v6Pdl",
        "outputId": "1c823540-320e-4dd6-8bde-38d1c68fe96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Рэй Брэдберри  Тестовая_8 вместе\n",
            "Добавление файла \"(Рэй Брэдберри) Тестовая_8 вместе.txt\" в класс \"Рэй Брэдберри\"\n",
            "Клиффорд_Саймак  Тестовая_2 вместе\n",
            "Добавление файла \"(Клиффорд_Саймак) Тестовая_2 вместе.txt\" в класс \"Клиффорд_Саймак\"\n",
            "Макс Фрай  Тестовая_2 вместе\n",
            "Добавление файла \"(Макс Фрай) Тестовая_2 вместе.txt\" в класс \"Макс Фрай\"\n",
            "Клиффорд_Саймак  Обучающая_5 вместе\n",
            "Добавление файла \"(Клиффорд_Саймак) Обучающая_5 вместе.txt\" в класс \"Клиффорд_Саймак\"\n",
            "Рэй Брэдберри  Обучающая_22 вместе\n",
            "Добавление файла \"(Рэй Брэдберри) Обучающая_22 вместе.txt\" в класс \"Рэй Брэдберри\"\n",
            "Стругацкие  Тестовая_2 вместе\n",
            "Добавление файла \"(Стругацкие) Тестовая_2 вместе.txt\" в класс \"Стругацкие\"\n",
            "Булгаков  Тестовая_2 вместе\n",
            "Добавление файла \"(Булгаков) Тестовая_2 вместе.txt\" в класс \"Булгаков\"\n",
            "Макс Фрай  Обучающая_5 вместе\n",
            "Добавление файла \"(Макс Фрай) Обучающая_5 вместе.txt\" в класс \"Макс Фрай\"\n",
            "Булгаков  Обучающая_5 вместе\n",
            "Добавление файла \"(Булгаков) Обучающая_5 вместе.txt\" в класс \"Булгаков\"\n",
            "О. Генри  Обучающая_50 вместе\n",
            "Добавление файла \"(О. Генри) Обучающая_50 вместе.txt\" в класс \"О. Генри\"\n",
            "Стругацкие  Обучающая_5 вместе\n",
            "Добавление файла \"(Стругацкие) Обучающая_5 вместе.txt\" в класс \"Стругацкие\"\n",
            "О. Генри  Тестовая_20 вместе\n",
            "Добавление файла \"(О. Генри) Тестовая_20 вместе.txt\" в класс \"О. Генри\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_train[0][:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KUrY7g-Fxd6",
        "outputId": "4f4c4186-c778-43a4-8ae9-753ff43b404a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ﻿451° по Фаренгейту   ДОНУ КОНГДОНУ С БЛАГОДАРНОСТЬЮ   Если тебе дадут линованную бумагу, пиши поперёк.  Хуан Рамон Хименес   Часть 1  ОЧАГ И САЛАМАНДРА   Жечь было наслаждением. Какое-то особое насл\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "IOaBt0qw704Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed = morph.parse('глокая')"
      ],
      "metadata": {
        "id": "5niyrjE-76ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed[0].normal_form"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2mc2DJwV77ob",
        "outputId": "11bed0fc-f579-4c6c-8416-96058f0f7c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'глокать'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkJKkBgGE3Qg",
        "outputId": "f8a92d22-ab11-4ebd-db0d-b94475ddfd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parse(word='глокая', tag=OpencorporaTag('GRND,impf,intr pres'), normal_form='глокать', score=0.27950310559006214, methods_stack=((<DictionaryAnalyzer>, 'окая', 15, 67), (<UnknownPrefixAnalyzer>, 'гл')))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoprocess_texts = [gensim.utils.simple_preprocess(txt) for txt in text_train]\n",
        "norm_autoprocess_texts=[]\n",
        "for txt in autoprocess_texts:\n",
        "  text=[]\n",
        "  #print(txt[:10])\n",
        "  for word in txt:\n",
        "    word1=morph.parse(word)[0].normal_form\n",
        "    #print(word1)\n",
        "    if(word1):\n",
        "      text.append(word1)\n",
        "  #print(text)\n",
        "  norm_autoprocess_texts.append(text)"
      ],
      "metadata": {
        "id": "vgf2eUrnqJXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoprocess_texts[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTA6RWWeAfND",
        "outputId": "6607c806-4229-4e71-db5f-add75a440967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['по',\n",
              " 'фаренгейту',\n",
              " 'дону',\n",
              " 'конгдону',\n",
              " 'благодарностью',\n",
              " 'если',\n",
              " 'тебе',\n",
              " 'дадут',\n",
              " 'линованную',\n",
              " 'бумагу']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_autoprocess_texts[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB-BtKzsBG4q",
        "outputId": "10697f45-a800-49a2-a60a-f3f1e8ab7924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['по',\n",
              " 'фаренгейт',\n",
              " 'дон',\n",
              " 'конгдон',\n",
              " 'благодарность',\n",
              " 'если',\n",
              " 'ты',\n",
              " 'дать',\n",
              " 'линовать',\n",
              " 'бумага']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y7ENaLG6_wn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание нормализованного и ненормализованного словарей выводы о уменьшении длинны словаря после нормализации."
      ],
      "metadata": {
        "id": "gdQYfMzYKNEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary_auto = [gensim.corpora.Dictionary([text]) for text in autoprocess_texts]\n",
        "dictionary_norm_auto = [gensim.corpora.Dictionary([text]) for text in norm_autoprocess_texts]\n",
        "len_dictionary_auto = [len(dictionary.token2id) for dictionary in dictionary_auto]\n",
        "len_dictionary_norm_auto = [len(dictionary.token2id) for dictionary in dictionary_norm_auto]\n",
        "med=0\n",
        "med1=0\n",
        "for i in range(len(len_dictionary_auto)):\n",
        "  print(CLASS_LIST[i],\"     : до\",len_dictionary_auto[i],\"после\",len_dictionary_norm_auto[i],\"уменьшилась\",len_dictionary_auto[i]-len_dictionary_norm_auto[i],\"уменьшилась%\",int((len_dictionary_auto[i]-len_dictionary_norm_auto[i])/len_dictionary_auto[i]*100*100)/100)\n",
        "  med+=len_dictionary_auto[i]-len_dictionary_norm_auto[i]\n",
        "  med1+=len_dictionary_auto[i]\n",
        "print(\"уменьшилась в среднем\",int(med/med1*100*100)/100,\"%\")\n"
      ],
      "metadata": {
        "id": "bDreZem0IkO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a51fcf-2d0b-4b8d-92fb-02b7069d030d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Рэй Брэдберри      : до 34186 после 15061 уменьшилась 19125 уменьшилась% 55.94\n",
            "Клиффорд_Саймак      : до 30650 после 13889 уменьшилась 16761 уменьшилась% 54.68\n",
            "Макс Фрай      : до 57418 после 21868 уменьшилась 35550 уменьшилась% 61.91\n",
            "Стругацкие      : до 47972 после 20643 уменьшилась 27329 уменьшилась% 56.96\n",
            "Булгаков      : до 39879 после 17780 уменьшилась 22099 уменьшилась% 55.41\n",
            "О. Генри      : до 35389 после 16499 уменьшилась 18890 уменьшилась% 53.37\n",
            "уменьшилась в среднем 56.92 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выводы. Длинна уменьшается больше чем на половину. Обучение ускорится точность может потерятся, пробовать надо и результат смотреть.   \n",
        "Дополнительная функция, определение форм и частей речи   OpencorporaTag('GRND,impf,intr pres')   Можно дополнительно использовать в обучении. \n",
        "Всегда или нет применять не ясно. Надо смотреть как влияет на результат."
      ],
      "metadata": {
        "id": "0lD42KcZES6y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LApUxV25dBu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VPdQtoN3dByS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D-8jtIWSdB1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTw2Y9e_dB4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aqePo9D9dB8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPes-VQhb3DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dr6sgUhmtaFe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}